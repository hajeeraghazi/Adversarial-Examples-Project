# ğŸš€ Adversarial Examples Project

A complete implementation of **adversarial attacks (FGSM, PGD)**, **defenses (adversarial training)**, and **robustness evaluation** using deep learning models.
This project is structured into **backend**, **frontend**, **models**, and **results** for clarity and scalability.

---

# ğŸ“ Folder Structure

```
Adversarial-Examples-Project/
â”‚
â”œâ”€â”€ backend/                # All Python backend code (training, attacks, evaluation)
â”‚     â”œâ”€â”€ training.py
â”‚     â”œâ”€â”€ adversarial_backend.py
â”‚     â””â”€â”€ utils/            (optional helpers if added later)
â”‚
â”œâ”€â”€ frontend/               # UI components (React/Next.js/Tailwind if completed)
â”‚     â”œâ”€â”€ Dashboard.tsx
â”‚     â”œâ”€â”€ globals.css
â”‚     â”œâ”€â”€ tailwind.config.js
â”‚     â””â”€â”€ ...more files i
â”‚
â”œâ”€â”€ models/                 # Trained model weights
â”‚     â”œâ”€â”€ standard_model.pth
â”‚     â”œâ”€â”€ robust_model.pth
â”‚     â”œâ”€â”€ ensemble_model_0.pth
â”‚     â”œâ”€â”€ ensemble_model_1.pth
â”‚     â”œâ”€â”€ ensemble_model_2.pth
â”‚
â”œâ”€â”€ results/                # Robustness plots & outputs
â”‚     â”œâ”€â”€ standard_robustness.png
â”‚     â”œâ”€â”€ robust_robustness.png
â”‚     â””â”€â”€ ensemble_robustness.png
â”‚
â””â”€â”€ README.md
```

---

# ğŸ§° Installation & Setup

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/hajeeraghazi/Adversarial-Examples-Project.git
cd Adversarial-Examples-Project
```

### 2ï¸âƒ£ Create & activate a virtual environment

Windows:

```bash
python -m venv venv
venv\Scripts\activate
```

Mac/Linux:

```bash
python -m venv venv
source venv/bin/activate
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r backend/requirements.txt
```

âœ” All Python dependencies are now installed.

---

# ğŸ“‚ Dataset Setup (MNIST / CIFAR-10)

Your backend automatically downloads datasets.

Create a data folder:

```bash
mkdir data
```

Datasets will be downloaded automatically into:

```
data/mnist/
data/cifar10/
```

No manual download required âœ”

---

# ğŸ” Optional: Create `.env.local`

Inside project root:

```
DATA_DIR=./data
MODEL_DIR=./models
RESULTS_DIR=./results
DEVICE=cuda        # or cpu
SEED=42
```

Not required to run basic scripts, but recommended for paths.

---

# ğŸš€ How to Run the Project

All backend scripts are inside `/backend`.

Move into backend folder:

```bash
cd backend
```

---

## ğŸ¯ 1. Train a Standard Model

```bash
python training.py --mode standard --dataset mnist --epochs 10
```

## ğŸ”’ 2. Train a Robust (Adversarially-Trained) Model

```bash
python training.py --mode robust --dataset cifar10 --epochs 10
```

---

## âš¡ 3. Generate Adversarial Examples (FGSM / PGD)

### FGSM:

```bash
python adversarial_backend.py --attack fgsm --eps 0.03 --dataset mnist
```

### PGD:

```bash
python adversarial_backend.py --attack pgd --eps 0.03 --steps 40 --dataset cifar10
```

---

## ğŸ” 4. Evaluate Clean vs Adversarial Robustness

```bash
python adversarial_backend.py --evaluate
```

Outputs saved to:

```
results/standard_robustness.png
results/robust_robustness.png
results/ensemble_robustness.png
```

---

# ğŸ–¥ Optional: Frontend (Dashboard)

Your **frontend** folder contains UI components for visualization.

### If using Next.js or Vite:

```bash
cd frontend
npm install
npm run dev
```

*(Add package.json when frontend is completed)*

---

# ğŸ“Š Features

* FGSM & PGD adversarial attack implementation
* Standard model training
* Robust (adversarial) training
* Ensemble model evaluation
* Robustness visualization plots
* Clean folder separation for scalability
* Optional frontend dashboard

---

# ğŸ§ª Ideal For

* ML/AI coursework
* Security & adversarial ML research
* Portfolio & interviews
* Experimenting with attack/defense strategies

---

# ğŸ“ Future Enhancements

* Add more attacks (CW, AutoAttack)
* Add Model Zoo
* Build full frontend dashboard
* Add TensorBoard logging

